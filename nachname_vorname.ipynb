{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Data Analytics SoSe 2021\n",
    "## Gruppenmitglieder: Anja Stricker, Annika Stadelmann"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Aufgabe 1\n",
    "#### (Datenvorbereitung)\n",
    "Lesen Sie den unter der o.g. Adresse verfugbaren Tankstellendatensatz zum Stand 31.05.2021\n",
    "in einen DataFrame namens df stations ein. Dieser soll in dieser Aufgabe fur die weitere\n",
    "Verwendung vorbereitet werden."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                   uuid                     name    brand  \\\n",
       "0  0e18d0d3-ed38-4e7f-a18e-507a78ad901d  OIL! Tankstelle München     OIL!   \n",
       "1  44e2bdb7-13e3-4156-8576-8326cdd20459           bft Tankstelle      NaN   \n",
       "2  ad812258-94e7-473d-aa80-d392f7532218   bft Bonn-Bad Godesberg      bft   \n",
       "3  e52d755d-4be7-4962-a917-3b0139e6f352          Esso Tankstelle     ESSO   \n",
       "4  e52a5d92-33c6-4c77-b6cd-ea90ca1c7c62     Friedrich Dankelmann  Markant   \n",
       "\n",
       "                street house_number post_code     city   latitude  longitude  \\\n",
       "0  Eversbuschstraße 33          NaN     80999  München  48.180700  11.460900   \n",
       "1       Schellengasse            53     36304  Alsfeld  50.752009   9.279039   \n",
       "2    Godesberger Allee           55     53175     Bonn  50.695100   7.142760   \n",
       "3  OSNABRUECKER STR. 5                  49163   BOHMTE  52.358250   8.304064   \n",
       "4     Strangenhäuschen           10     52070   Aachen  50.801680   6.110960   \n",
       "\n",
       "             first_active                                  openingtimes_json  \n",
       "0  1970-01-01 01:00:00+01  {\"openingTimes\":[{\"applicable_days\":192,\"perio...  \n",
       "1  1970-01-01 01:00:00+01  {\"openingTimes\":[{\"applicable_days\":63,\"period...  \n",
       "2  1970-01-01 01:00:00+01  {\"openingTimes\":[{\"applicable_days\":31,\"period...  \n",
       "3  2014-03-18 16:45:31+01  {\"openingTimes\":[{\"applicable_days\":31,\"period...  \n",
       "4  2014-03-18 16:45:31+01  {\"openingTimes\":[{\"applicable_days\":63,\"period...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uuid</th>\n      <th>name</th>\n      <th>brand</th>\n      <th>street</th>\n      <th>house_number</th>\n      <th>post_code</th>\n      <th>city</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>first_active</th>\n      <th>openingtimes_json</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0e18d0d3-ed38-4e7f-a18e-507a78ad901d</td>\n      <td>OIL! Tankstelle München</td>\n      <td>OIL!</td>\n      <td>Eversbuschstraße 33</td>\n      <td>NaN</td>\n      <td>80999</td>\n      <td>München</td>\n      <td>48.180700</td>\n      <td>11.460900</td>\n      <td>1970-01-01 01:00:00+01</td>\n      <td>{\"openingTimes\":[{\"applicable_days\":192,\"perio...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>44e2bdb7-13e3-4156-8576-8326cdd20459</td>\n      <td>bft Tankstelle</td>\n      <td>NaN</td>\n      <td>Schellengasse</td>\n      <td>53</td>\n      <td>36304</td>\n      <td>Alsfeld</td>\n      <td>50.752009</td>\n      <td>9.279039</td>\n      <td>1970-01-01 01:00:00+01</td>\n      <td>{\"openingTimes\":[{\"applicable_days\":63,\"period...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ad812258-94e7-473d-aa80-d392f7532218</td>\n      <td>bft Bonn-Bad Godesberg</td>\n      <td>bft</td>\n      <td>Godesberger Allee</td>\n      <td>55</td>\n      <td>53175</td>\n      <td>Bonn</td>\n      <td>50.695100</td>\n      <td>7.142760</td>\n      <td>1970-01-01 01:00:00+01</td>\n      <td>{\"openingTimes\":[{\"applicable_days\":31,\"period...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>e52d755d-4be7-4962-a917-3b0139e6f352</td>\n      <td>Esso Tankstelle</td>\n      <td>ESSO</td>\n      <td>OSNABRUECKER STR. 5</td>\n      <td></td>\n      <td>49163</td>\n      <td>BOHMTE</td>\n      <td>52.358250</td>\n      <td>8.304064</td>\n      <td>2014-03-18 16:45:31+01</td>\n      <td>{\"openingTimes\":[{\"applicable_days\":31,\"period...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>e52a5d92-33c6-4c77-b6cd-ea90ca1c7c62</td>\n      <td>Friedrich Dankelmann</td>\n      <td>Markant</td>\n      <td>Strangenhäuschen</td>\n      <td>10</td>\n      <td>52070</td>\n      <td>Aachen</td>\n      <td>50.801680</td>\n      <td>6.110960</td>\n      <td>2014-03-18 16:45:31+01</td>\n      <td>{\"openingTimes\":[{\"applicable_days\":63,\"period...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "df_stations = pd.read_csv(\"2021-05-31-stations.csv\")\n",
    "df_stations.head()"
   ]
  },
  {
   "source": [
    "a) Untersuchen Sie den Datensatz auf fehlende Werte und setzen Sie ggf. eine geeignete Strategie um, um mit diesen zu verfahren. Begrunden Sie Ihr Vorgehen."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "uuid                    0\n",
       "name                    0\n",
       "brand                 670\n",
       "street                  3\n",
       "house_number         2940\n",
       "post_code               3\n",
       "city                    4\n",
       "latitude                0\n",
       "longitude               0\n",
       "first_active            0\n",
       "openingtimes_json       0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "df_stations.isnull().sum()"
   ]
  },
  {
   "source": [
    "Im folgenden werden nur noch die Spalten betrachtet die einen NaN Wert über 0 haben.\n",
    "Alle Spalten mit 0 haben keine NaN Werte und müssen demnach nicht nochmal kontrolliert werden.\n",
    "\n",
    "NaN Werte werden durch passende andere Werte ersetzt."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations[\"brand\"] = df_stations[\"brand\"].fillna(\"other\")\n",
    "df_stations[\"openingtimes_json\"] = df_stations[\"openingtimes_json\"].replace(\"{}\", \"empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "uuid                    0\n",
       "name                    0\n",
       "brand                   0\n",
       "street                  3\n",
       "house_number         2940\n",
       "post_code               3\n",
       "city                    4\n",
       "latitude                0\n",
       "longitude               0\n",
       "first_active            0\n",
       "openingtimes_json       0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "df_stations.isnull().sum()"
   ]
  },
  {
   "source": [
    "Jetzt werden fehlende Einträge von street, house_number, city und post_code mit geopy ermittelt und ersetzt."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from geopy.geocoders import Nominatim\n",
    "# geolocator = Nominatim(user_agent=\"DA_stud\")\n",
    "# df = pd.DataFrame()\n",
    "\n",
    "# for i in df_stations.loc[df_stations[\"street\"].isnull() | df_stations[\"house_number\"].isnull() | df_stations[\"city\"].isnull() | df_stations[\"post_code\"].isnull()].index:\n",
    "#     data = df_stations.iloc[i]\n",
    "#     if ((data[\"latitude\"] <= 90.0) & (data[\"latitude\"] >= -90.0) & (data[\"longitude\"] <= 180.0) & (data[\"longitude\"] >= -180.0) \n",
    "#     & (data[\"latitude\"] != 0.0) & (data[\"longitude\"] != 0.0)):\n",
    "#         location = geolocator.reverse(str(data[\"latitude\"]) + \", \" + str(data[\"longitude\"]))\n",
    "#         adressData = location.raw[\"address\"]\n",
    "#         if \"road\" in adressData:\n",
    "#             df_stations.at[i, \"street\"] = adressData[\"road\"]\n",
    "#         if \"house_number\" in adressData:\n",
    "#             df_stations.at[i, \"house_number\"] = adressData[\"house_number\"]\n",
    "#         if \"town\" in adressData:\n",
    "#             df_stations.at[i, \"city\"] = adressData[\"town\"]\n",
    "#         if \"postcode\" in adressData:\n",
    "#             df_stations.at[i, \"post_code\"] = adressData[\"postcode\"]\n",
    "\n",
    "# df_stations[df_stations[\"city\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.65it/s]\n"
     ]
    }
   ],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent=\"DA_stud\")\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for i in tqdm(df_stations.loc[df_stations[\"street\"].isnull() | df_stations[\"city\"].isnull() | df_stations[\"post_code\"].isnull()].index):\n",
    "    data = df_stations.iloc[i]\n",
    "    if ((data[\"latitude\"] <= 90.0) & (data[\"latitude\"] >= -90.0) & (data[\"longitude\"] <= 180.0) & (data[\"longitude\"] >= -180.0) \n",
    "    & (data[\"latitude\"] != 0.0) & (data[\"longitude\"] != 0.0)):\n",
    "        location = geolocator.reverse(str(data[\"latitude\"]) + \", \" + str(data[\"longitude\"]))\n",
    "        adressData = location.raw[\"address\"]\n",
    "        if \"road\" in adressData:\n",
    "            df_stations.at[i, \"street\"] = adressData[\"road\"]\n",
    "        if \"town\" in adressData:\n",
    "            df_stations.at[i, \"city\"] = adressData[\"town\"]\n",
    "        if \"postcode\" in adressData:\n",
    "            df_stations.at[i, \"post_code\"] = adressData[\"postcode\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 2940/2940 [24:29<00:00,  2.00it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(df_stations.loc[df_stations[\"house_number\"].isnull()].index):\n",
    "    data = df_stations.iloc[i]\n",
    "    if ((data[\"latitude\"] <= 90.0) & (data[\"latitude\"] >= -90.0) & (data[\"longitude\"] <= 180.0) & (data[\"longitude\"] >= -180.0) \n",
    "    & (data[\"latitude\"] != 0.0) & (data[\"longitude\"] != 0.0)):\n",
    "        location = geolocator.reverse(str(data[\"latitude\"]) + \", \" + str(data[\"longitude\"]))\n",
    "        adressData = location.raw[\"address\"]\n",
    "        if \"house_number\" in adressData:\n",
    "            df_stations.at[i, \"house_number\"] = adressData[\"house_number\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid non-printable character U+00A0 (<ipython-input-1-5ec2e95185d4>, line 1)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-5ec2e95185d4>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    df_stations[\"street\"] = df_stations[\"street\"].fillna(\"\")\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid non-printable character U+00A0\n"
     ]
    }
   ],
   "source": [
    "df_stations[\"street\"] = df_stations[\"street\"].fillna(\"\")\n",
    "df_stations[\"post_code\"] = df_stations[\"post_code\"].fillna(\"\")\n",
    "df_stations[\"city\"] = df_stations[\"city\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'notnull'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-84958ddb9335>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_stations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"street\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"post_code\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"city\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m#address we need to geocode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'notnull'"
     ]
    }
   ],
   "source": [
    "for i in tqdm(df_stations.loc[(df_stations[\"latitude\"] == 0.0) & (df_stations[\"longitude\"] == 0.0)].index):\n",
    "    data = df_stations.iloc[i]\n",
    "\n",
    "    if ((data[\"street\"] == \"\") & (data[\"post_code\"] == \"\") & (data[\"city\"] == \"\")):\n",
    "\n",
    "        #address we need to geocode\n",
    "        loc = data[\"street\"] + data[\"post_code\"] + data[\"city\"]\n",
    "        \n",
    "        #applying geocode method to get the location\n",
    "        location = geolocator.geocode(loc)\n",
    "        \n",
    "        #printing address and coordinates\n",
    "        print(location.address)\n",
    "        print((location.latitude, location.longitude))\n",
    "\n",
    "        if \"house_number\" in adressData:\n",
    "            df_stations.at[i, \"latitude\"] = location.latitude\n",
    "            df_stations.at[i, \"longitude\"] = location.longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations.drop(df_stations.loc[(df_stations[\"latitude\"] == 0.0) & (df_stations[\"longitude\"] == 0.0)], axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "source": [
    "Prüfen ob Cities NaN sind"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einträge die City, Post_Code und Coordinaten NaN haben werden gelöscht."
   ]
  },
  {
   "source": [
    "Citys die einen NaN Wert haben, aber einen Postcode, werden mit den anderen Postcode einträgen verglichen und erhalten den Namen der City."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-43-306eed9bfc74>, line 3)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-43-306eed9bfc74>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    if (len(test) > 0)\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def findCityWithPostcode(row):\n",
    "    test = df_stations[\"city\"][(df_stations[\"post_code\"] == row[\"post_code\"]) & (df_stations[\"city\"].notnull())].item()\n",
    "    if (len(test) > 0):\n",
    "        return test\n",
    "    else\n",
    "        return \"\"\n",
    "df_stations[\"city\"] = df_stations[[\"city\", \"post_code\"]].apply(lambda x: findCityWithPostcode(x) if x[\"city\"] is np.nan else x[\"city\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations[\"house_number\"] = df_stations[\"house_number\"].fillna(0)\n",
    "df_stations = df_stations.dropna(subset=[\"city\"])\n",
    "df_stations.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations.to_csv(\"df_stations.csv\", index=True)"
   ]
  },
  {
   "source": [
    "b) Transformieren Sie die Spalten brand, street und city, sodass die Werte jeweils nur\n",
    "in Großbuchstaben ausgeben werden."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations[\"brand\"] = df_stations[\"brand\"].str.upper()\n",
    "df_stations[\"street\"] = df_stations[\"street\"].str.upper()\n",
    "df_stations[\"city\"] = df_stations[\"city\"].str.upper()"
   ]
  },
  {
   "source": [
    "c) Uberprüfen Sie, ob der Datensatz Duplikate enth ¨ alt und entfernen Sie diese ggf. Ein Dupli- ¨\n",
    "kat liege dann vor, wenn zwei Tankstellen in den Spalten name, street, house number\n",
    "und post code ubereinstimmen. Geben Sie aus, wie viele Duplikate ermittelt und entfernt ¨\n",
    "wurden."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations[[\"name\", \"street\", \"house_number\", \"post_code\"]].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_stations.duplicated(subset = {\"name\", \"street\", \"house_number\", \"post_code\"}, keep = \"first\") \n",
    "\n",
    "df_stations.drop_duplicates(subset = {\"name\", \"street\", \"house_number\", \"post_code\"}, keep =  \"first\", inplace = True)\n",
    "df_stations[[\"name\", \"street\", \"house_number\", \"post_code\"]].duplicated().sum()"
   ]
  },
  {
   "source": [
    "Es wurden 52 Duplikate ermittelt"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_stations[[\"name\", \"street\", \"house_number\", \"post_code\"]] = df_stations[[\"name\", \"street\", \"house_number\", \"post_code\"]].drop_duplicates()"
   ]
  },
  {
   "source": [
    "d) Untersuchen Sie die Spalten longitude und latitude auf unphysikalische Werte, indem Sie zunachst deren Verteilung in einem Histogramm visualisieren. Entfernen oder kor- ¨\n",
    "rigieren Sie anschließend die Eintrage zu denjenigen Tankstellen, bei denen Sie unphysi- ¨\n",
    "kalische Werte festgestellt haben. Zeichnen Sie anschließend erneut Histogramme fur die ¨\n",
    "beiden Spalten longitude und latitude."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Zuerst analysieren wir die Daten."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(df_stations[\"latitude\"], 50, label='latitude')\n",
    "plt.hist(df_stations[\"longitude\"], 50, label='longitude')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title(\"Geo Data\")\n",
    "plt.xlabel('coordinates') \n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "Bei Longitude ist ein Ausreißer beim Wert 0 zu erkennen. Diese werden im Folgenden gefiltert.\n",
    "Ebenso sind unphysikalische Werte zu erkennen, welche ebenfalls korrigiert werden."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations = df_stations.loc[(df_stations[\"longitude\"] != 0.0) & (df_stations[\"latitude\"] != 0.0)]\n",
    "df_stations = df_stations.loc[(df_stations[\"latitude\"] <= 90.0) & (df_stations[\"latitude\"] >= -90.0) & (df_stations[\"longitude\"] <= 180.0) & (df_stations[\"longitude\"] >= -180.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_stations[\"latitude\"], 10, label='latitude')\n",
    "plt.hist(df_stations[\"longitude\"], 50, label='longitude')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title(\"Geo Data\")\n",
    "plt.xlabel('coordinates') \n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "Jetzt sehen wir die korrekte Koordinaten Daten"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "e) Reichern Sie den Tankstellendatensatz um die Spalte state an, die das Bundesland enthalten soll, in dem sich die Tankstelle befindet. Erzeugen Sie durch Filterung einen DataFrame\n",
    "namens df_stations_BY, der die Informationen zu allen Tankstellen in Bayern enthalt."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations = df_stations.reset_index(drop=True)\n",
    "df_stations.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RangeIndex(start=16241, stop=16251, step=1)"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "df_stations[-10:].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.67it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0                     Bayern\n",
       "1                     Hessen\n",
       "2        Nordrhein-Westfalen\n",
       "3              Niedersachsen\n",
       "4        Nordrhein-Westfalen\n",
       "                ...         \n",
       "16286     Schleswig-Holstein\n",
       "16287          Niedersachsen\n",
       "16288          Niedersachsen\n",
       "16289          Niedersachsen\n",
       "16290    Nordrhein-Westfalen\n",
       "Name: state, Length: 16291, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "# for i in tqdm(df_stations.index):\n",
    "#     data = df_stations.iloc[i]\n",
    "#     location = geolocator.reverse(str(data[\"latitude\"]) + \", \" + str(data[\"longitude\"]))\n",
    "#     adressData = location.raw[\"address\"]\n",
    "#     if \"state\" in adressData:\n",
    "#         df_stations.at[i, \"state\"] = adressData[\"state\"]\n",
    "\n",
    "# df_stations[\"state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bundesland_plz = pd.read_csv(\"zuordnung_plz_ort.csv\")\n",
    "df_bundesland_plz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plz_bundesland_dict = {}\n",
    "\n",
    "for i, j in zip(df_bundesland_plz.plz, df_bundesland_plz.bundesland):\n",
    "    plz_bundesland_dict[str(i)] = j\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations[\"state\"] = df_stations[\"post_code\"].map(plz_bundesland_dict)\n",
    "df_stations.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(df_stations.loc[df_stations[\"state\"].isnull()].index):\n",
    "    data = df_stations.iloc[i]\n",
    "    location = geolocator.reverse(str(data[\"latitude\"]) + \", \" + str(data[\"longitude\"]))\n",
    "    adressData = location.raw[\"address\"]\n",
    "    if \"state\" in adressData:\n",
    "        df_stations.at[i, \"state\"] = adressData[\"state\"]\n",
    "\n",
    "df_stations[\"state\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations[df_stations[\"state\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations.to_csv(\"State_checkpoint.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations = pd.read_csv(\"State_checkpoint.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations_BY = df_stations.loc[df_stations[\"state\"] == \"Bayern\"]"
   ]
  },
  {
   "source": [
    "Lesen Sie nun den Preise-Datensatz aus dem GitLab-Repository in einen DataFrame namens\n",
    "df_prices_BY ein. Dieser wurde durch Filterung der auf der Tankerkonig-Seite verf ¨ ugbaren ¨\n",
    "Preise-Datensatze erzeugt und enth ¨ alt die Angaben zur historischen Preisen und Preis ¨ anderungen ¨\n",
    "an den Tankstellen in Bayern im Betrachtungszeitraum zwischen Januar 2018 und Mai 2021."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices_BY = pd.read_csv(\"prices_BY.csv\")"
   ]
  },
  {
   "source": [
    "f) Untersuchen Sie die Kraftstoffpreise auf Ausreißer und entfernen Sie diese ggf."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices_BY.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(df_prices_BY[\"diesel\"], 50, label='diesel')\n",
    "plt.hist(df_prices_BY[\"e5\"], 50, label='e5')\n",
    "plt.hist(df_prices_BY[\"e10\"], 50, label='e10')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title(\"Geo Data\")\n",
    "plt.xlabel('coordinates') \n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices_BY[\"e10\"] = df_prices_BY[\"e10\"].replace(0.000, np.nan)\n",
    "df_prices_BY.loc[df_prices_BY[\"e10\"] < 0.5] = np.nan\n",
    "df_prices_BY[\"e5\"] = df_prices_BY[\"e5\"].replace(0.000, np.nan)\n",
    "df_prices_BY[\"diesel\"] = df_prices_BY[\"diesel\"].replace(0.000, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(df_prices_BY[\"diesel\"], 30, label='diesel')\n",
    "plt.hist(df_prices_BY[\"e5\"], 30, label='e5')\n",
    "plt.hist(df_prices_BY[\"e10\"], 30, label='e10')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title(\"Geo Data\")\n",
    "plt.xlabel('coordinates') \n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "g) Uberf ¨ uhren Sie die Spalte ¨ date in ein DateTime-Format."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices_BY[\"date\"] = pd.to_datetime(df_prices_BY[\"date\"], infer_datetime_format=True, utc=True)\n",
    "df_prices_BY[\"date\"].head()"
   ]
  },
  {
   "source": [
    "### Aufgabe 2 \n",
    "#### (Explorative Datenanalyse)\n",
    "In dieser Aufgabe sind erste einfache Analysen durchzufuhren und Visualisierungen zu erstellen"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "a) Wie viele Tankstellen gibt es insgesamt in Deutschland? Wie viele pro Bundesland?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tankstellenZahl = len(df_stations)\n",
    "# tankstellenZahl\n",
    "\n",
    "# need state df\n",
    "\n",
    "haeufigkeitTankstellen = {\"Deutschland\": 0, \"Baden-Wuerttemberg\": 0, \"Bayern\": 0, \"Berlin\": 0, \"Brandenburg\": 0, \"Bremen\": 0, \"Hamburg\": 0, \"Hessen\": 0, \"Mecklenburg-Vorpommern\": 0, \"Niedersachsen\": 0, \"Nordrhein-Westfalen\": 0, \"Rheinland-Pfalz\": 0, \"Saarland\": 0, \"Sachsen\": 0, \"Sachsen-Anhalt\": 0, \"Schleswig-Holstein\": 0, \"Thueringen\": 0, \"other\": 0}\n",
    "\n",
    "for x in df_stations[\"state\"]:\n",
    "    if x == \"Baden-Württemberg\":\n",
    "        haeufigkeitTankstellen[\"Baden-Wuerttemberg\"] += 1\n",
    "    if x == \"Bayern\":\n",
    "        haeufigkeitTankstellen[\"Bayern\"] += 1\n",
    "    if x == \"Berlin\":\n",
    "        haeufigkeitTankstellen[\"Berlin\"] += 1\n",
    "    if x == \"Brandenburg\":\n",
    "        haeufigkeitTankstellen[\"Brandenburg\"] += 1\n",
    "    if x == \"Bremen\":\n",
    "        haeufigkeitTankstellen[\"Bremen\"] += 1\n",
    "    if x == \"Hamburg\":\n",
    "        haeufigkeitTankstellen[\"Hamburg\"] += 1\n",
    "    if x == \"Hessen\":\n",
    "        haeufigkeitTankstellen[\"Hessen\"] += 1\n",
    "    if x == \"Mecklenburg-Vorpommern\":\n",
    "        haeufigkeitTankstellen[\"Mecklenburg-Vorpommern\"] += 1\n",
    "    if x == \"Niedersachsen\":\n",
    "        haeufigkeitTankstellen[\"Niedersachsen\"] += 1\n",
    "    if x == \"Nordrhein-Westfalen\":\n",
    "        haeufigkeitTankstellen[\"Nordrhein-Westfalen\"] += 1\n",
    "    if x == \"Rheinland-Pfalz\":\n",
    "        haeufigkeitTankstellen[\"Rheinland-Pfalz\"] += 1\n",
    "    if x == \"Saarland\":\n",
    "        haeufigkeitTankstellen[\"Saarland\"] += 1\n",
    "    if x == \"Sachsen\":\n",
    "        haeufigkeitTankstellen[\"Sachsen\"] += 1\n",
    "    if x == \"Sachsen-Anhalt\":\n",
    "        haeufigkeitTankstellen[\"Sachsen-Anhalt\"] += 1\n",
    "    if x == \"Schleswig-Holstein\":\n",
    "        haeufigkeitTankstellen[\"Schleswig-Holstein\"] += 1\n",
    "    if x == \"Thüringen\":\n",
    "        haeufigkeitTankstellen[\"Thueringen\"] += 1\n",
    "    if x == \"other\":\n",
    "        haeufigkeitTankstellen[\"other\"] += 1\n",
    "    haeufigkeitTankstellen[\"Deutschland\"] += 1\n",
    "\n",
    "haeufigkeitTankstellen\n",
    "# df_stations.isnull().sum()"
   ]
  },
  {
   "source": [
    "b) Welches sind die zehn Tankstellenmarken mit den meisten Niederlassungen in Deutschland?\n",
    "Wie viele Niederlassungen sind es jeweils?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meisteMarken = list(df_stations['brand'].value_counts()[0:10].index)\n",
    "\n",
    "def Convert(lst):\n",
    "    res_dct = {lst[i]: 0 for i in range(0, len(lst), 1)}\n",
    "    return res_dct\n",
    "\n",
    "lst = Convert(meisteMarken)\n",
    "\n",
    "for x in df_stations[\"brand\"]:\n",
    "    if x in lst:\n",
    "        lst[x] += 1\n",
    "\n",
    "lst"
   ]
  },
  {
   "source": [
    "c) Welcher Anteil der Tankstellen hat sonntags geoffnet?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations[\"openingtimes_json\"]\n",
    "\n",
    "openingTimes = list(df_stations['openingtimes_json'])\n",
    "openOnSunday = {\"Sonntags_geöffnet\": 0, \"Sonntags_geschlossen\": 0}\n",
    "\n",
    "def Convert(lst):\n",
    "    res_dct = {lst[i]: 0 for i in range(0, len(lst), 1)}\n",
    "    return res_dct\n",
    "\n",
    "lst = Convert(openingTimes)\n",
    "\n",
    "for x in df_stations[\"openingtimes_json\"]:\n",
    "    if x[\"applicable_days\"] << 6:\n",
    "        openOnSunday[\"Sonntags_geöffnet\"] += 1\n",
    "    else:\n",
    "        openOnSunday[\"Sonntags_geschlossen\"] += 1\n",
    "\n",
    "openOnSunday"
   ]
  },
  {
   "source": [
    "d) Visualisieren Sie in einem Kreisdiagramm die Zusammensetzung des Marktes in freie Tankstellen und Markentankstellen. Nehmen Sie vereinfachend an, dass eine Tankstelle dann\n",
    "eine freie Tankstelle ist, wenn sie gemaß der Spalte ¨ brand einer Marke angehort, die bun- ¨\n",
    "desweit hochstens 20 Niederlassungen betreibt."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand = list(df_stations['brand'].value_counts().index)\n",
    "\n",
    "def Convert(lst):\n",
    "    res_dct = {lst[i]: 0 for i in range(0, len(lst), 1)}\n",
    "    return res_dct\n",
    "\n",
    "lst = Convert(brand)\n",
    "\n",
    "for x in df_stations[\"brand\"]:\n",
    "    if x in lst:\n",
    "        lst[x] += 1\n",
    "\n",
    "tankstellenListe = {\"Markentankstellen\": 0, \"Freie Tankstellen\": 0}\n",
    "\n",
    "for x in lst.values():\n",
    "    if x > 20:\n",
    "        tankstellenListe[\"Markentankstellen\"] += x\n",
    "    else:\n",
    "        tankstellenListe[\"Freie Tankstellen\"] += x\n",
    "tankstellenListe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pie_label_formatter(x):\n",
    "    return '{:.2f}%'.format(x)\n",
    "\n",
    "plt.pie(tankstellenListe.values(), labels = tankstellenListe.keys(), autopct=pie_label_formatter)\n",
    "plt.title(\"Anzahl der freien und Markentankstellen\")\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "e) Wie haufig wird an den bayerischen Tankstellen durchschnittlich pro Tag im Betrachtungs- ¨\n",
    "zeitraum ein Datensatz an die Markttransparenzstelle fur Kraftstoffe ¨ ubermittelt? "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_prices_BY[\"date\"].groupby(df_prices_BY[\"date\"].dt.date).count()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.mean()"
   ]
  },
  {
   "source": [
    "f) In welchen zehn bayerischen Stadten war der durchschnittliche Diesel-Preis im Betrach- ¨\n",
    "tungszeitraum 2018-2021 am hochsten und wie hoch war er jeweils? In welchen zehn ¨\n",
    "Stadten war er am geringsten und wie hoch war er jeweils? "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "source": [
    "g) Erstellen Sie mit folium eine interaktive Karte, auf der die einzelnen Tankstellen in Bayern\n",
    "als Marker (in einem Marker-Cluster) eingezeichnet sind. Beim Klick auf einen Marker soll\n",
    "der Name der Tankstelle und deren Adresse angezeigt werden."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "source": [
    "### Aufgabe 3\n",
    "#### (Analyse der historischen Entwicklung der Kraftstoffpreise)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "a) In welchem Monat im Betrachtungszeitraum waren die Kraftstoffpreise fur Diesel in Bay- ¨\n",
    "ern durchschnittlich am hochsten? In welchem am geringsten? Wie hoch waren die durch- ¨\n",
    "schnittlichen Preise jeweils?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "source": [
    "b) Ermitteln Sie die Jahresdurchschnitte fur die einzelnen Kraftstoffsorten in den Jahren 2018- ¨\n",
    "2021 fur die bayerischen Tankstellen. Visualisieren Sie diese in einem geeigneten Dia- ¨\n",
    "gramm. Lassen sich Trends erkennen?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "source": [
    "c) Visualisieren Sie auf geeignete Weise den zeitlichen Verlauf der Preise fur die Kraftstoffe ¨\n",
    "Diesel und Super E5 und Super E10 an den bayerischen Tankstellen zwischen 2018 und\n",
    "2021. Beschreiben und interpretieren Sie Ihre Beobachtungen."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "source": [
    "### Aufgabe 4\n",
    "#### (Abhangigkeit zwischen dem Roh ¨ olpreis und den Kraftstoffpreisen)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "a) Untersuchen Sie jeweils den Zusammenhang zwischen den Kraftstoffpreisen fur Diesel bzw. ¨\n",
    "Super E5 und dem Roholpreis. Berechnen Sie dazu die Tagesmittelwerte f ¨ ur die Kraftstoff- ¨\n",
    "preise fur alle Tage im Betrachtungszeitraum 2018-2021 (f ¨ ur die bayerischen Tankstellen) ¨\n",
    "und stellen Sie diese jeweils den Tagesschlusskursen fur die Roh ¨ olsorte Brent Crude Oil ¨\n",
    "(offentlich verf ¨ ugbar) in zwei Streudiagrammen (eines f ¨ ur Diesel und eines f ¨ ur E5) ge- ¨\n",
    "genuber. Laden Sie die verwendeten ¨ Olpreis-Daten in Form einer CSV-Datei mit Ihrer Ab- ¨\n",
    "gabe auf Moodle hoch."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "source": [
    "b) Berechnen Sie jeweils fur Diesel und E5 den empirischen Korrelationskoeffizienten zwi- ¨\n",
    "schen den Roholpreisen und den Tagesmittelwerten der Kraftstoffpreise."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "source": [
    "c) Diskutieren Sie, ob lineare Modelle sinnvoll waren, um die Zusammenh ¨ ange zwischen dem ¨\n",
    "Roholpreis und den Preisen f ¨ ur Diesel bzw. E5 darzustellen."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "source": [
    "### Aufgabe 5\n",
    "#### (Einfluss des Wettbewerbs auf die Kraftstoffpreise in Bayern)\n",
    "Untersuchen Sie, welchen Einfluss der Wettbewerb zwischen mehreren Tankstellen auf die Preisgestaltung hat. Ermitteln Sie dazu zunachst f ¨ ur jede Tankstelle in Bayern, wie viele Tankstellen ¨\n",
    "sich im Umkreis von 5km Umgebung zu ihr befindet. Speichern Sie diese Angabe in einer Spalte namens neighbors. Speichern Sie den resultierenden DataFrame df stations BY als\n",
    "CSV-Datei namens stations BY.csv und laden Sie diese mit Ihrer Abgabe auf Moodle hoch.\n",
    "Stellen Sie zunachst m ¨ ogliche Hypothesen auf und untersuchen Sie diese anschließend, indem Sie ¨\n",
    "geeignete Auswertungen und Visualisierungen erstellen."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "source": [
    "### Aufgabe 6\n",
    "#### (Tanken in Amberg, Interaktives Diagramm)\n",
    "Herr Sparfuchs, der als Rentner zeitlich flexibel ist, mochte wissen, wann und wo er in Am- ¨\n",
    "berg derzeit am gunstigsten tanken kann. Erstellen Sie dazu ein geeignetes interaktives Dia- ¨\n",
    "gramm mit Plotly, um die Kraftstoffpreise an den Tankstellen in Amberg zu analysieren, und\n",
    "leiten Sie Empfehlungen fur Herrn Sparfuchs ab. Erstellen Sie f ¨ ur die Analyse zwei DataFrames ¨\n",
    "namens df stations amberg und df prices amberg, die aus Filterung der Tankstellenund Preisdatensatze hervorgehen, und verwenden Sie ausschließlich diese f ¨ ur die Erzeugung des ¨\n",
    "Plotly-Diagramms. Dokumentieren Sie Ihre Analyseergebnisse."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  }
 ]
}